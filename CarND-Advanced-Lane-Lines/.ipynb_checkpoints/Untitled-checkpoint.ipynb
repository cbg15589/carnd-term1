{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import pickle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read in and make a list of calibration images\n",
    "images = glob.glob('C:\\carnd-term1\\CarND-Advanced-Lane-Lines\\camera_cal\\calibration*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images\n",
    "\n",
    "objpoints = [] # 3D points in the real world space\n",
    "imgpoints = [] # 2d points in image plane\n",
    "\n",
    "# Prepare onject points, like (0,0,0), (1,0,0) ....,(8,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) # x, y coordinates\n",
    "\n",
    "plt.subplots(figsize=(20, 8))\n",
    "i = 0\n",
    "for fname in images:\n",
    "    # Read in each image\n",
    "    img = mpimg.imread(fname)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If corners are found, add object points, image points\n",
    "    if ret == True:\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        # draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        plt.subplot(4,5, 1 + i)\n",
    "        i+=1\n",
    "        plt.imshow(img)\n",
    "        \n",
    "# Calibrate Camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Undistort images\n",
    "plt.subplots(figsize=(20, 8))\n",
    "i = 0\n",
    "for fname in images:\n",
    "    # Read in each image\n",
    "    img = mpimg.imread(fname)\n",
    "    \n",
    "    # Undistort and print image\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    plt.subplot(4,5, 1 + i)\n",
    "    i+=1\n",
    "    plt.imshow(dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"C:\\carnd-term1\\CarND-Advanced-Lane-Lines\\camera_cal\\wide_dist_pickle.p\", \"wb\" ) )\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = mpimg.imread('C:\\carnd-term1\\CarND-Advanced-Lane-Lines\\camera_cal\\calibration1.jpg')\n",
    "\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_calibration(path):\n",
    "    #Load image calibration\n",
    "    calibration_file = path\n",
    "\n",
    "    with open(calibration_file, mode='rb') as f:\n",
    "        calibration = pickle.load(f)\n",
    "    \n",
    "    mtx, dist = calibration['mtx'], calibration['dist']\n",
    "    \n",
    "    return mtx, dist\n",
    "\n",
    "def undistort(img,mtx,dist):\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read in and make a list of road images\n",
    "road_images = glob.glob('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\test*.jpg')\n",
    "\n",
    "\n",
    "# Undistort images\n",
    "plt.subplots(figsize=(20, 20))\n",
    "i = 0\n",
    "for fname in road_images:\n",
    "    # Read in each image\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # Undistort, save and print image\n",
    "    mtx, dist = load_calibration('C:\\carnd-term1\\CarND-Advanced-Lane-Lines\\camera_cal\\wide_dist_pickle.p')\n",
    "    dst = undistort(img, mtx, dist)\n",
    "    plt.subplot(9,2, 1 + i)\n",
    "    i+=1\n",
    "    plt.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))\n",
    "    cv2.imwrite('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\undistort_test' + str(i) + '.jpg',dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Edit this function to create your own pipeline.\n",
    "def color_gradient_threshold(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 255\n",
    "\n",
    "    return color_binary, combined_binary\n",
    "\n",
    "src = np.float32([[283,663],[594,451],[686,451],[1019,663]])\n",
    "dst = np.float32([[325,720],[325,0],[950,0],[950,720]]) \n",
    "\n",
    "def warp_image(img,src,dst):\n",
    "    \n",
    "    # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read in and make a list of undistorted road images\n",
    "undistorted_road_images = glob.glob('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\undistort_test*.jpg')\n",
    "\n",
    "\n",
    "i=0\n",
    "for fname in undistorted_road_images:\n",
    "    \n",
    "    img = cv2.imread(fname)\n",
    "    result, result_combined = color_gradient_threshold(img)\n",
    "    i+=1\n",
    "    cv2.imwrite('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\color_grad_test' + str(i) + '.jpg',result_combined)\n",
    "\n",
    "    # Plot the result\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "\n",
    "    ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "    ax2.imshow(result)\n",
    "    ax2.set_title('Color&Gradient Threshold Result', fontsize=40)\n",
    "    \n",
    "    ax3.imshow(result_combined, cmap='gray')\n",
    "    ax3.set_title('Combined Result', fontsize=40)\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    warped = warp_image(result_combined,src,dst)\n",
    "    cv2.imwrite('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\warped_test' + str(i) + '.jpg',warped)\n",
    "\n",
    "    f2, (ax4, ax5) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f2.tight_layout()\n",
    "\n",
    "    ax4.imshow(result_combined, cmap='gray')\n",
    "    ax4.set_title('Combined Result', fontsize=40)\n",
    "    ax4.add_patch(plt.Polygon(src,fill=None,ec = 'r',lw = 3))\n",
    "\n",
    "    ax5.imshow(warped, cmap='gray')\n",
    "    ax5.set_title('Warped Image', fontsize=40)\n",
    "    ax5.add_patch(plt.Polygon(dst,fill=None,ec = 'r',lw = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def find_window_centroids(warped, window_width, window_height, margin):\n",
    "\n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "\n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "\n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(warped.shape[1]/2)\n",
    "\n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "\n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(warped.shape[0]/window_height)):\n",
    "            # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(warped[int(warped.shape[0]-(level+1)*window_height):int(warped.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,warped.shape[1]))\n",
    "        l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,warped.shape[1]))\n",
    "        r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "def mask_lines(warped, window_centroids = None, previous_fit = None, window_width = 50,window_height = 80, margin = 50):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # If we found any window centers\n",
    "    if window_centroids != None:\n",
    "        #print('Got Window Centroids')\n",
    "        \n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(warped)\n",
    "        r_points = np.zeros_like(warped)\n",
    "\n",
    "        # Go through each level and draw the windows \t\n",
    "        for level in range(0,len(window_centroids)):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "            r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "            l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "            r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "        template_3channels = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "        windows_warped = cv2.addWeighted(warpage, 1, template_3channels, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "        masked_warped = cv2.bitwise_and(warped, template)\n",
    "    \n",
    "    elif previous_fit != None:\n",
    "        #print('No Window Centroids')\n",
    "        nonzero = warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        left_fit = previous_fit[0]\n",
    "        right_fit = previous_fit[1]\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "        \n",
    "        \n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "        \n",
    "        window_img = np.zeros_like(warped)\n",
    "        l_mask = cv2.fillPoly(window_img, np.int_([left_line_pts]), (255,255, 255))\n",
    "        r_mask = cv2.fillPoly(window_img, np.int_([right_line_pts]), (255,255, 255))\n",
    "        template = np.array(l_mask+r_mask,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "        template_3channels = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "        windows_warped = cv2.addWeighted(warpage, 1, template_3channels, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "        masked_warped = cv2.bitwise_and(warped, template)\n",
    "        #f, (ax4, ax5) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        #f.tight_layout()\n",
    "        #ax4.imshow(windows_warped)\n",
    "        #ax5.imshow(masked_warped)\n",
    "        #print(l_mask.shape)\n",
    "    \n",
    "        \n",
    "    # If no window centers found, just display orginal road image\n",
    "    else:\n",
    "        windows_warped = np.array(cv2.merge((warped,warped,warped)),np.uint8)\n",
    "        masked_warped = warped\n",
    "\n",
    "    \n",
    "    return masked_warped, windows_warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# window settings\n",
    "window_width = 50 \n",
    "window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 50 # How much to slide left and right for searching\n",
    "previous_fit = None\n",
    "\n",
    "warped_images = glob.glob('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\warped_test*.jpg')\n",
    "plt.subplots(figsize=(20, 20))\n",
    "i = 0\n",
    "for fname in warped_images:\n",
    "    # Read in a thresholded image\n",
    "    warped = mpimg.imread(fname)\n",
    "   \n",
    "    window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "\n",
    "    masked_warped, windows_warped =  mask_lines(warped, window_centroids,previous_fit, window_width,window_height, margin)\n",
    "    \n",
    "    \n",
    "    # Display the final results\n",
    "    plt.subplot(9,2, 1 + i)\n",
    "    i+=1\n",
    "    plt.imshow(windows_warped)\n",
    "    cv2.imwrite('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\warped_windows_test' + str(i) + '.jpg',windows_warped)\n",
    "    cv2.imwrite('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\warped_masked_test' + str(i) + '.jpg',masked_warped)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fit_lines(masked_warped):\n",
    "    \n",
    "    pixels_left = cv2.findNonZero(masked_warped[:,:int(masked_warped.shape[1]/2)])\n",
    "    pixels_right = cv2.findNonZero(masked_warped[:,int(masked_warped.shape[1]/2):])\n",
    "    pixels_right[:,0,0] = pixels_right[:,0,0] + int(masked_warped.shape[1]/2)\n",
    "    #print(pixels.shape)\n",
    "    #print(pixels_left.shape)\n",
    "    #print(pixels_right.shape)\n",
    "    #print(pixels_left[0])\n",
    "    # Generate some fake data to represent lane-line pixels\n",
    "\n",
    "    lefty = pixels_left[:,0,1]\n",
    "    righty = pixels_right[:,0,1]\n",
    "\n",
    "    leftx = pixels_left[:,0,0]\n",
    "    rightx = pixels_right[:,0,0]\n",
    "    \n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/736 # meters per pixel in x dimension\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    y_eval = masked_warped.shape[0]\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    #Calculate offset from line center\n",
    "    left_line_x = left_fit[0]*y_eval**2 + left_fit[1]*y_eval + left_fit[2]\n",
    "    right_line_x = right_fit[0]*y_eval**2 + right_fit[1]*y_eval + right_fit[2]\n",
    "    lane_center = (left_line_x + right_line_x)/2\n",
    "    \n",
    "    offset = (lane_center - masked_warped.shape[1]/2)*xm_per_pix\n",
    "    return left_fit, right_fit , left_fit_cr,right_fit_cr, left_curverad, right_curverad, pixels_left, pixels_right, offset, left_line_x, right_line_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "masked_warped_images = glob.glob('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\warped_masked_test*.jpg')\n",
    "\n",
    "plt.subplots(figsize=(20, 20))\n",
    "i = 0\n",
    "for fname in masked_warped_images:    \n",
    "    \n",
    "    masked_warped = mpimg.imread(fname)   \n",
    "    \n",
    "    left_fit, right_fit , left_fit_cr,right_fit_cr, left_curverad, right_curverad, pixels_left, pixels_right, offset, left_line_x, right_line_x = fit_lines(masked_warped)\n",
    "\n",
    "    # Fit a second order polynomial to pixel positions in each fake lane line\n",
    "    ploty = np.linspace(0, int(masked_warped.shape[0])-1, num=int(masked_warped.shape[0]))# to cover same y-range as image\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Plot up the point data\n",
    "    plt.subplot(9,2, 1 + i)\n",
    "    mark_size = 3\n",
    "    plt.plot(pixels_left[:,0,0], pixels_left[:,0,1], 'o', color='red', markersize=mark_size)\n",
    "    plt.plot(pixels_right[:,0,0], pixels_right[:,0,1], 'o', color='blue', markersize=mark_size)\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(0, 720)\n",
    "    plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "    plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "    plt.gca().invert_yaxis() # to visualize as we do the images\n",
    "    i+=1\n",
    "    \n",
    "    # Now our radius of curvature is in meters\n",
    "    print(left_curverad, 'm', right_curverad, 'm')\n",
    "    # Example values: 632.1 m    626.2 m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        self.detected_counter = 0\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "        # fit values of the last n fits of the line\n",
    "        self.recent_fits = None\n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #difference in fit coefficients between last and new fits (percent)\n",
    "        self.diffsper = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "def process_image(img):\n",
    "    mtx, dist = load_calibration('C:\\carnd-term1\\CarND-Advanced-Lane-Lines\\camera_cal\\wide_dist_pickle.p')\n",
    "    undist = undistort(img, mtx, dist)\n",
    "    result, result_combined = color_gradient_threshold(undist)\n",
    "    src = np.float32([[283,663],[594,451],[686,451],[1019,663]])\n",
    "    dst = np.float32([[325,720],[325,0],[950,0],[950,720]]) \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(result_combined, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    # window settings\n",
    "    #left_line.bestx = random.random()\n",
    "    #print(left_line.bestx)\n",
    "    window_width = 50 \n",
    "    window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "    margin = 50 # How much to slide left and right for searching\n",
    "    #print(left_line.current_fit[0] == False)\n",
    "    previous_fit = np.array([left_line.current_fit, right_line.current_fit])\n",
    "    #print(previous_fit.shape)\n",
    "    #print(previous_fit == False)\n",
    "    if (previous_fit == False).any() or left_line.detected_counter == 10 or right_line.detected_counter == 10:\n",
    "        print('Calculating Centroids')\n",
    "        window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "        left_line.best_fit = None\n",
    "        left_line.recent_fits = None\n",
    "        right_line.best_fit = None\n",
    "        right_line.recent_fits = None\n",
    "        left_line.detected_counter = 0\n",
    "        right_line.detected_counter = 0\n",
    "    else:\n",
    "        window_centroids = None        \n",
    "        \n",
    "    masked_warped, windows_warped =  mask_lines(warped, window_centroids,previous_fit, window_width,window_height, margin)\n",
    "    left_fit, right_fit , left_fit_cr,right_fit_cr, left_curverad, right_curverad, pixels_left, pixels_right, offset, left_line_x, right_line_x = fit_lines(masked_warped)\n",
    "    \n",
    "    \n",
    "\n",
    "    left_line.detected = True \n",
    "    right_line.detected = True\n",
    "    left_line.recent_xfitted.append(left_line_x)\n",
    "    left_line.recent_xfitted = left_line.recent_xfitted[-10:]\n",
    "    right_line.recent_xfitted.append(right_line_x)\n",
    "    right_line.recent_xfitted = right_line.recent_xfitted[-10:]\n",
    "    \n",
    "    if left_line.best_fit != None:\n",
    "        left_line.diffs = left_line.best_fit - left_fit\n",
    "        left_line.diffsper = (left_line.diffs / left_line.best_fit) * 100\n",
    "\n",
    "    if right_line.best_fit != None:\n",
    "        right_line.diffs = right_line.best_fit - right_fit\n",
    "        right_line.diffsper = (right_line.diffs / right_line.best_fit) * 100\n",
    "    \n",
    "    \n",
    "    if left_line.recent_fits != None: \n",
    "        if (abs(left_line.diffsper[0]) > 300) or (abs(left_line.diffsper[1]) > 300) or (abs(left_line.diffsper[2]) > 3000):\n",
    "            left_line.detected = False\n",
    "            left_line.detected_counter += 1\n",
    "        else: \n",
    "            left_line.recent_fits = np.column_stack((left_line.recent_fits,left_fit))\n",
    "            left_line.recent_fits = left_line.recent_fits[:,-10:]\n",
    "            left_line.best_fit = [np.mean(left_line.recent_fits[0,:]),np.mean(left_line.recent_fits[1,:]),np.mean(left_line.recent_fits[2,:])]\n",
    "            \n",
    "    else:\n",
    "        left_line.recent_fits = left_fit\n",
    "        left_line.best_fit = left_fit\n",
    "        \n",
    "    if right_line.recent_fits != None: \n",
    "        if (abs(right_line.diffsper[0]) > 300) or (abs(right_line.diffsper[1]) > 300) or (abs(right_line.diffsper[2]) > 300):\n",
    "                right_line.detected = False\n",
    "                right_line.detected_counter += 1\n",
    "        else:\n",
    "            right_line.recent_fits = np.column_stack((right_line.recent_fits,right_fit))\n",
    "            right_line.recent_fits = right_line.recent_fits[:,-10:]\n",
    "            right_line.best_fit = [np.mean(right_line.recent_fits[0,:]),np.mean(right_line.recent_fits[1,:]),np.mean(right_line.recent_fits[2,:])] \n",
    "    else:\n",
    "        right_line.recent_fits = right_fit\n",
    "        right_line.best_fit = right_fit\n",
    "    \n",
    "    left_line.bestx = None\n",
    "    right_line.bestx = None\n",
    "\n",
    "    \n",
    "    if left_line.radius_of_curvature != None:\n",
    "        left_line.radius_of_curvature = (left_line.radius_of_curvature*9 + left_curverad)/10 \n",
    "        left_line.line_base_pos = (left_line.line_base_pos*9 + offset)/10 \n",
    "    else:\n",
    "        left_line.radius_of_curvature = left_curverad\n",
    "        left_line.line_base_pos = offset\n",
    "        \n",
    "    if right_line.radius_of_curvature != None:\n",
    "        right_line.radius_of_curvature = (right_line.radius_of_curvature*9 + right_curverad)/10 \n",
    "        right_line.line_base_pos = (right_line.line_base_pos*9 + offset)/10\n",
    "    else:\n",
    "        right_line.radius_of_curvature = right_curverad\n",
    "        right_line.line_base_pos = offset\n",
    "        \n",
    "        \n",
    "    left_line.current_fit = left_fit\n",
    "    right_line.current_fit = right_fit\n",
    "    \n",
    "    ploty = np.linspace(0, int(masked_warped.shape[0])-1, num=int(masked_warped.shape[0]))# to cover same y-range as image\n",
    "    left_fitx = left_line.best_fit[0]*ploty**2 + left_line.best_fit[1]*ploty + left_line.best_fit[2]\n",
    "    right_fitx = right_line.best_fit[0]*ploty**2 + right_line.best_fit[1]*ploty + right_line.best_fit[2]\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, M, (img.shape[1], img.shape[0]), flags=cv2.WARP_INVERSE_MAP) \n",
    "    # Combine the result with the original image\n",
    "    output = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    curverad = (left_line.radius_of_curvature + right_line.radius_of_curvature)/2\n",
    "    output_image = cv2.putText(output,'Line detected: L ' + str(left_line.detected) + ' R ' + str(right_line.detected),(50,70), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    output_image = cv2.putText(output,'L Last X Values:' + str([round(elem, 4) for elem in left_line.recent_xfitted]),(50,130), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    output_image = cv2.putText(output,'R Last X Values:' + str([round(elem, 4) for elem in right_line.recent_xfitted]),(50,190), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    output_image = cv2.putText(output,'Average X value: L ' + str(left_line.bestx) + ' R ' + str(right_line.bestx),(50,250), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    output_image = cv2.putText(output,'Average Fit: L ' + str(left_line.best_fit) + ' R ' + str(right_line.best_fit),(50,310), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    output_image = cv2.putText(output,'Current Fit: L ' + str(left_line.current_fit) + ' R ' + str(right_line.current_fit),(50,370), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    output_image = cv2.putText(output,'Best Fit Difference: L ' + str(left_line.diffs) + ' R ' + str(right_line.diffs),(50,430), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    output_image = cv2.putText(output,'Best Fit Difference Percent: L ' + str(left_line.diffsper) + ' R ' + str(right_line.diffsper),(50,490), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    output_image = cv2.putText(output,'Curve Radio:' + str(right_line.radius_of_curvature),(50,550), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    output_image = cv2.putText(output,'Offset From Center:' + str(right_line.line_base_pos),(50,610), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "    return output_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read in and make a list of road images\n",
    "road_images = glob.glob('C:\\\\carnd-term1\\\\CarND-Advanced-Lane-Lines\\\\test_images\\\\test*.jpg')\n",
    "for fname in road_images:\n",
    "    img = masked_warped = mpimg.imread(fname)  \n",
    "    output_image = process_image(img)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(output_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: could not find imageio's ffmpeg executable:\n",
      "[WinError 5] Access is denied: 'C:\\\\ProgramData\\\\Miniconda3\\\\envs\\\\carnd-term1-gpu\\\\lib\\\\site-packages\\\\imageio\\\\resources\\\\ffmpeg\\\\ffmpeg.win32.exe'\n",
      "WARNING:py.warnings:C:\\ProgramData\\Miniconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\skimage\\filter\\__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n",
      "[MoviePy] >>>> Building video project_video_out.mp4\n",
      "[MoviePy] Writing video project_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1261 [00:00<?, ?it/s]WARNING:py.warnings:C:\\ProgramData\\Miniconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\ipykernel\\__main__.py:75: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "\n",
      "WARNING:py.warnings:C:\\ProgramData\\Miniconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\ipykernel\\__main__.py:48: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "\n",
      "WARNING:py.warnings:C:\\ProgramData\\Miniconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\ipykernel\\__main__.py:52: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "\n",
      "WARNING:py.warnings:C:\\ProgramData\\Miniconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\ipykernel\\__main__.py:57: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "\n",
      "WARNING:py.warnings:C:\\ProgramData\\Miniconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\ipykernel\\__main__.py:70: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "\n",
      " 25%|███████████████████▉                                                           | 319/1261 [01:11<03:33,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▍                                                        | 358/1261 [01:20<03:24,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████████▉                                                       | 382/1261 [01:25<03:19,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████████▌                                                      | 393/1261 [01:28<03:12,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████                                                     | 416/1261 [01:33<03:11,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████████▌                                                   | 439/1261 [01:38<03:09,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████████████████▎                                                  | 452/1261 [01:41<03:04,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|█████████████████████████████                                                  | 463/1261 [01:44<02:58,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████                                                 | 480/1261 [01:48<02:54,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████▉                                                | 494/1261 [01:51<02:51,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████████▊                                               | 507/1261 [01:54<02:51,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████████████▋                                              | 522/1261 [01:57<02:47,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▍                                             | 534/1261 [02:00<02:39,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|███████████████████████████████████                                            | 560/1261 [02:06<02:28,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████▊                                           | 571/1261 [02:08<02:25,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████████████████████████████████████▍                                          | 582/1261 [02:11<02:32,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▏                                        | 610/1261 [02:17<02:20,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▍                                  | 710/1261 [02:40<02:05,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████▎                                | 740/1261 [02:46<01:55,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████                                | 751/1261 [02:49<01:54,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████████████████████████████████▊                               | 763/1261 [02:52<01:51,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████▌                              | 775/1261 [02:54<01:47,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████▎                             | 788/1261 [02:57<01:46,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████████████████████████████████████▏                | 993/1261 [03:44<00:58,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|███████████████████████████████████████████████████████████████▏              | 1021/1261 [03:50<00:53,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████████████████▊            | 1063/1261 [04:00<00:44,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Centroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [04:45<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_out.mp4 \n",
      "\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "video_output = 'project_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "video_output_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time video_output_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_output = 'challenge_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "video_output_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time video_output_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_output = 'harder_challenge_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "video_output_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time video_output_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
