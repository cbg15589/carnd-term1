{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Warning: could not find imageio's ffmpeg executable:\n",
      "[WinError 5] Access is denied: 'C:\\\\ProgramData\\\\Miniconda3\\\\envs\\\\carnd-term1-gpu\\\\lib\\\\site-packages\\\\imageio\\\\resources\\\\ffmpeg\\\\ffmpeg.win32.exe'\n",
      "WARNING:py.warnings:C:\\ProgramData\\Miniconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\skimage\\filter\\__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n",
      "\n",
      "WARNING:py.warnings:C:\\ProgramData\\Miniconda3\\envs\\carnd-term1-gpu\\lib\\site-packages\\keras\\models.py:257: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_data\\yolo-voc.h5 model, anchors, and classes loaded.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import argparse\n",
    "import colorsys\n",
    "import imghdr\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from yad2k.models.keras_yolo import yolo_eval, yolo_head\n",
    "\n",
    "# Code from Allanzelener repository (https://github.com/allanzelener/YAD2K)\n",
    "\n",
    "# Define model assets location\n",
    "model_path = 'model_data\\\\yolo-voc.h5'\n",
    "assert model_path.endswith('.h5'), 'Keras model must be a .h5 file.'\n",
    "anchors_path = 'model_data\\\\yolo-voc_anchors.txt'\n",
    "classes_path = 'model_data\\\\pascal_classes.txt'\n",
    "test_path = 'images\\\\'\n",
    "output_path = 'images_out\\\\'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    print('Creating output path {}'.format(output_path))\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "sess = K.get_session()\n",
    "\n",
    "with open(classes_path) as f:\n",
    "    class_names = f.readlines()\n",
    "class_names = [c.strip() for c in class_names]\n",
    "\n",
    "with open(anchors_path) as f:\n",
    "    anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    anchors = np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "yolo_model = load_model(model_path)\n",
    "\n",
    "# Verify model, anchors, and classes are compatible\n",
    "num_classes = len(class_names)\n",
    "num_anchors = len(anchors)\n",
    "# TODO: Assumes dim ordering is channel last\n",
    "model_output_channels = yolo_model.layers[-1].output_shape[-1]\n",
    "assert model_output_channels == num_anchors * (num_classes + 5), \\\n",
    "    'Mismatch between model and given anchor and class sizes. ' \\\n",
    "    'Specify matching anchors and classes with --anchors_path and ' \\\n",
    "    '--classes_path flags.'\n",
    "print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "# Check if model is fully convolutional, assuming channel last order.\n",
    "model_image_size = yolo_model.layers[0].input_shape[1:3]\n",
    "is_fixed_size = model_image_size != (None, None)\n",
    "\n",
    "# Generate colors for drawing bounding boxes.\n",
    "hsv_tuples = [(x / len(class_names), 1., 1.)for x in range(len(class_names))]\n",
    "colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),colors))\n",
    "random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "random.seed(None)  # Reset seed to default.\n",
    "\n",
    "# Generate output tensor targets for filtered bounding boxes.\n",
    "# TODO: Wrap these backend operations with Keras layers.\n",
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "input_image_shape = K.placeholder(shape=(2, ))\n",
    "boxes, scores, classes = yolo_eval(yolo_outputs,input_image_shape,score_threshold=0.3,iou_threshold=0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 boxes for test1.jpg\n",
      "car 0.83 (797, 407) (949, 501)\n",
      "car 0.85 (1037, 407) (1268, 510)\n",
      "Found 0 boxes for test2.jpg\n",
      "Found 1 boxes for test3.jpg\n",
      "car 0.72 (866, 411) (959, 467)\n",
      "Found 2 boxes for test4.jpg\n",
      "car 0.82 (801, 406) (946, 501)\n",
      "car 0.84 (1023, 406) (1258, 504)\n",
      "Found 2 boxes for test5.jpg\n",
      "car 0.73 (802, 405) (941, 489)\n",
      "car 0.85 (1059, 401) (1280, 518)\n",
      "Found 2 boxes for test6.jpg\n",
      "car 0.78 (798, 407) (943, 503)\n",
      "car 0.86 (983, 404) (1213, 507)\n",
      "Found 2 boxes for test7.jpg\n",
      "car 0.81 (796, 405) (945, 503)\n",
      "car 0.83 (986, 401) (1205, 501)\n"
     ]
    }
   ],
   "source": [
    "# Test model on some images\n",
    "for image_file in os.listdir(test_path):\n",
    "    try:\n",
    "        image_type = imghdr.what(os.path.join(test_path, image_file))\n",
    "        if not image_type:\n",
    "            continue\n",
    "    except IsADirectoryError:\n",
    "        continue\n",
    "\n",
    "    image = Image.open(os.path.join(test_path, image_file))\n",
    "    if is_fixed_size:  \n",
    "        resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "    else:\n",
    "        # Due to skip connection + max pooling in YOLO_v2, inputs must have\n",
    "        # width and height as multiples of 32.\n",
    "        new_image_size = (image.width - (image.width % 32),image.height - (image.height % 32))\n",
    "        resized_image = image.resize(new_image_size, Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    out_boxes, out_scores, out_classes = sess.run([boxes, scores, classes],\n",
    "        feed_dict={\n",
    "            yolo_model.input: image_data,\n",
    "            input_image_shape: [image.size[1], image.size[0]],\n",
    "            K.learning_phase(): 0\n",
    "        })\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "\n",
    "    font = ImageFont.truetype(font='font/FiraMono-Medium.otf',size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle([left + i, top + i, right - i, bottom - i],outline=colors[c])\n",
    "            draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)],fill=colors[c])\n",
    "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        del draw\n",
    "\n",
    "    image.save(os.path.join(output_path, image_file), quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pipeline to process a video frame with the model\n",
    "def process_image(image):\n",
    "    \n",
    "    image = Image.fromarray(image)\n",
    "    if is_fixed_size: \n",
    "        resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "    else:\n",
    "        # Due to skip connection + max pooling in YOLO_v2, inputs must have\n",
    "        # width and height as multiples of 32.\n",
    "        new_image_size = (image.width - (image.width % 32),image.height - (image.height % 32))\n",
    "        resized_image = image.resize(new_image_size, Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    out_boxes, out_scores, out_classes = sess.run([boxes, scores, classes],\n",
    "        feed_dict={\n",
    "            yolo_model.input: image_data,\n",
    "            input_image_shape: [image.size[1], image.size[0]],\n",
    "            K.learning_phase(): 0\n",
    "        })\n",
    "\n",
    "    font = ImageFont.truetype(font='font/FiraMono-Medium.otf',size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "        if predicted_class == 'car':\n",
    "            label = '{} {:.2f}'.format(predicted_class, score)\n",
    "\n",
    "            draw = ImageDraw.Draw(image)\n",
    "            label_size = draw.textsize(label, font)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "            #print(label, (left, top), (right, bottom))\n",
    "\n",
    "            if top - label_size[1] >= 0:\n",
    "                text_origin = np.array([left, top - label_size[1]])\n",
    "            else:\n",
    "                text_origin = np.array([left, top + 1])\n",
    "\n",
    "            for i in range(thickness):\n",
    "                draw.rectangle([left + i, top + i, right - i, bottom - i],outline=colors[c])\n",
    "                draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)],fill=colors[c])\n",
    "                draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "            del draw\n",
    "    image_out = np.asarray(image)\n",
    "    return image_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_out.mp4\n",
      "[MoviePy] Writing video project_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [01:54<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_out.mp4 \n",
      "\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "file='project_video.mp4'\n",
    "outfile='project_video_out.mp4'\n",
    "clip = VideoFileClip(file)\n",
    "out_clip = clip.fl_image(process_image) \n",
    "%time out_clip.write_videofile(outfile, audio=False)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
